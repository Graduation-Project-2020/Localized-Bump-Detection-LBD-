{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Training_Colab_MobNv2_Grayscale_FT3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0_MfiTHEdMZ",
        "colab_type": "text"
      },
      "source": [
        "**Import Packages**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AAlyx-mEZcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "import random\n",
        "import zipfile\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import re\n",
        "from distutils.dir_util import copy_tree\n",
        "import numpy as np\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjkz1KQUEjh7",
        "colab_type": "text"
      },
      "source": [
        "**Select The Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "repo_url = 'https://github.com/Tony607/object_detection_demo'\n",
        "\n",
        "# Number of training steps.\n",
        "num_steps = 5000  \n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {     \n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12},\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12},\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8},\n",
        "    'ssd_mobilenet_v1': {\n",
        "        'model_name': 'ssd_mobilenet_v1_coco_2018_01_28',\n",
        "        'pipeline_file': 'ssd_mobilenet_v1_coco.config',\n",
        "        'batch_size': 6}\n",
        "}\n",
        "\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCTyEsegEqTC",
        "colab_type": "text"
      },
      "source": [
        "**Clone the object_detection_demo repository.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc3DmvLQF3z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "95ba51f6-651a-4c20-bd03-993e2fd821d0"
      },
      "source": [
        "# Clone the object_detection_demo\n",
        "%cd /content\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'object_detection_demo'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Total 124 (delta 0), reused 0 (delta 0), pack-reused 124\u001b[K\n",
            "Receiving objects: 100% (124/124), 11.16 MiB | 5.19 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n",
            "/content/object_detection_demo\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pWTEOozE0b4",
        "colab_type": "text"
      },
      "source": [
        "**Install required packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6af0621-0eca-4d06-83cb-5e40c8e1f553"
      },
      "source": [
        "# Install required packages\n",
        "\n",
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git                #install models directory\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk    #protobuf used to generate py file from proto files\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib                  #used in utitlity functions\n",
        "!pip install -q pycocotools                                                #used in model_main.py\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.                     #generate python file from proto files\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!python object_detection/builders/model_builder_test.py                    #Creates a DetectionModel from proto files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 145113 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/models/research\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_experimental_model\n",
            "[       OK ] ModelBuilderTest.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 17 tests in 0.182s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzUZXyDLE6a7",
        "colab_type": "text"
      },
      "source": [
        "**Download The Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0C8Si7ejbiG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "8da3abae-c3a2-452e-84b9-826d194efcdf"
      },
      "source": [
        "# DataSet\n",
        "\n",
        "# AlexOnly_1280x720: https://www.kaggle.com/spaceengineer1/bumpdataset-alexonly-withoutnight-1280x720\n",
        "# AlexOnly_Greyscale (Selected Dataset): https://www.kaggle.com/spaceengineer1/alexonly-greyscale/data#\n",
        "\n",
        "!rm -rf /content/object_detection_demo/data/images\n",
        "try:\n",
        "  os.mkdir('/content/object_detection_demo/data/extracted/')\n",
        "except OSError:\n",
        "  pass\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://storage.googleapis.com/kaggle-data-sets/486198/906654/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1581959088&Signature=VAtb%2FftwTnG%2FS1HVqt%2Fnz5i2MiIv%2B0gaylnCvyKWIRsl2oaIUmDJU5JbKrKvObdTO6rP6LBamBBNiTOr1YN35DDqPTV4if%2BwmOYCrzmr3UhY96XdkSK2eHF%2FWr1WpCe2Vzv1T%2F6yhyn6wMxsP3iv%2BfDQJSD2avv3bpPEkvQFUWi2VM4WOjDzVaSouphYUr9sXkom1YqvAtn2Kd0qzRPizj4h4y7J1byOnjgL5PuqjnwY9XqMF18LzKA8Rfg8evVCTZVs2vQUlZj4WLprlONIdJAHOVcz52rqnmavxGB34MtbzNcQhV7B11f4kG3g56cf3Tfq4hr6C10iJ3aIMyyCUg%3D%3D&response-content-disposition=attachment%3B+filename%3Dalexonly-greyscale.zip\" \\\n",
        "    -O \"/tmp/bumps_dataset.zip\"\n",
        "\n",
        "local_zip = '/tmp/bumps_dataset.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/object_detection_demo/data/')\n",
        "zip_ref.close()\n",
        "\n",
        "%cd {repo_dir_path}\n",
        "\n",
        "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "test_record_fname = '/content/object_detection_demo/data/annotations/test.record'\n",
        "train_record_fname = '/content/object_detection_demo/data/annotations/train.record'\n",
        "label_map_pbtxt_fname = '/content/object_detection_demo/data/annotations/label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-17 15:34:24--  https://storage.googleapis.com/kaggle-data-sets/486198/906654/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1581959088&Signature=VAtb%2FftwTnG%2FS1HVqt%2Fnz5i2MiIv%2B0gaylnCvyKWIRsl2oaIUmDJU5JbKrKvObdTO6rP6LBamBBNiTOr1YN35DDqPTV4if%2BwmOYCrzmr3UhY96XdkSK2eHF%2FWr1WpCe2Vzv1T%2F6yhyn6wMxsP3iv%2BfDQJSD2avv3bpPEkvQFUWi2VM4WOjDzVaSouphYUr9sXkom1YqvAtn2Kd0qzRPizj4h4y7J1byOnjgL5PuqjnwY9XqMF18LzKA8Rfg8evVCTZVs2vQUlZj4WLprlONIdJAHOVcz52rqnmavxGB34MtbzNcQhV7B11f4kG3g56cf3Tfq4hr6C10iJ3aIMyyCUg%3D%3D&response-content-disposition=attachment%3B+filename%3Dalexonly-greyscale.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.194.128, 2404:6800:4003:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.194.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 243959824 (233M) [application/zip]\n",
            "Saving to: â€˜/tmp/bumps_dataset.zipâ€™\n",
            "\n",
            "/tmp/bumps_dataset. 100%[===================>] 232.66M  31.9MB/s    in 7.3s    \n",
            "\n",
            "2020-02-17 15:34:32 (31.9 MB/s) - â€˜/tmp/bumps_dataset.zipâ€™ saved [243959824/243959824]\n",
            "\n",
            "/content/object_detection_demo\n",
            "Successfully converted xml to csv.\n",
            "Generate `data/annotations/label_map.pbtxt`\n",
            "Successfully converted xml to csv.\n",
            "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0217 15:34:45.521040 140315997849472 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0217 15:34:45.529672 140315997849472 module_wrapper.py:139] From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/object_detection_demo/data/annotations/train.record\n",
            "WARNING:tensorflow:From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0217 15:34:52.132090 140656784131968 module_wrapper.py:139] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0217 15:34:52.139154 140656784131968 module_wrapper.py:139] From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/object_detection_demo/data/annotations/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRmOmxBSFHVc",
        "colab_type": "text"
      },
      "source": [
        "**Download Base Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "bc0b50a6-ce7b-4788-f2ac-991395d848b1"
      },
      "source": [
        "# Download base model\n",
        "\n",
        "%cd /content/models/research\n",
        "\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "0ab1f59e-3868-43a3-d7b6-af445db04580"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}\n",
        "\n",
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint   #to print the path of fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 66 root   root  4.0K Feb 17 15:35 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugBnd18bFWG2",
        "colab_type": "text"
      },
      "source": [
        "**Configuring a Training Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "34579fb4-768c-408f-ec57-0a2f0f3e195e"
      },
      "source": [
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n",
        "\n",
        "#get number of classes from label map\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "\n",
        "#edit config file with our hyperparameters    \n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"','fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)  # fine_tune_checkpoint\n",
        "    s = re.sub('(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)  # train tfrecord file.\n",
        "    s = re.sub('(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)     # test tfrecord files.\n",
        "    s = re.sub('label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)            # label_map_path\n",
        "    s = re.sub('batch_size: [0-9]+','batch_size: {}'.format(batch_size), s)                                 # Set training batch_size.\n",
        "    s = re.sub('num_steps: [0-9]+','num_steps: {}'.format(num_steps), s)                                    # Set training steps, num_steps\n",
        "    s = re.sub('num_classes: [0-9]+','num_classes: {}'.format(num_classes), s)                              # Set number of classes num_classes.\n",
        "    \n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvEChCfUFfWG",
        "colab_type": "text"
      },
      "source": [
        "**Mount Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQBwxsvS6oEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b7f406f-ddc6-4891-c9d9-74b74f8b80fa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        " \n",
        "copy_tree(\"/content/models/research/training/\", \"/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-115063.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1580382498.5360f0ae44c8',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-149992.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-155342.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1580372901.5360f0ae44c8',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1581793620.c723b17efbb3',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-115063.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-118367.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1580560826.712e43bc1923',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1581780142.c723b17efbb3',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-160000.meta',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-158078.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-121725.meta',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/checkpoint',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-156669.meta',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-155342.meta',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1581791505.c723b17efbb3',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-121725.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1581783672.c723b17efbb3',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581785508/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581785508/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581785508/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581779736/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581779736/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581779736/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580558623/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580558623/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580558623/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580390058/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580390058/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580390058/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581782059/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581782059/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581782059/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580565258/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580565258/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580565258/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581776519/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581776519/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581776519/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580374508/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580374508/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580374508/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580382265/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580382265/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580382265/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581789025/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581789025/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581789025/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581771261/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581771261/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581771261/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580562715/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580562715/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580562715/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580571814/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580571814/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1580571814/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581786604/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581958427/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581958427/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581958427/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581793400/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581773898/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581791105/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581795506/saved_model.pb',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581795506/variables/variables.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/export/Servo/1581795506/variables/variables.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-159410.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-146691.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1580563420.712e43bc1923',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-156669.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/graph.pbtxt',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-146691.meta',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1581789216.c723b17efbb3',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-160000.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-116713.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-158078.meta',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-158078.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-118367.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-156669.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-116713.meta',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1580390286.5360f0ae44c8',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1581771981.c723b17efbb3',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-148335.data-00000-of-00001',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1581777793.c723b17efbb3',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1580569371.712e43bc1923',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-159410.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-160000.index',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/events.out.tfevents.1581953882.449ef58f1542',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/eval_0/events.out.tfevents.1581954541.449ef58f1542',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-159410.meta',\n",
              " '/content/drive/My Drive/Detection Output/MobNv2GrSc_FT003/model.ckpt-155342.index']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqZ44fK7F1k0",
        "colab_type": "text"
      },
      "source": [
        "**Fine Tuning Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipTQaXQCD_TP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17e3137f-5ae0-44da-e0f2-0b3d17d6a5f8"
      },
      "source": [
        "# Fine Tunning -- ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶ðŸŽ¶\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# To Change -->\n",
        "\n",
        "!!!!!!!!!!! means it's important to change this hyperparameter\n",
        "\n",
        "# faster_rcnn_box_coder           Decrease, Doesn't Affect Much\n",
        "# image_resizer                   Keep as is,  High loss and very Low mAP at beginning but restored in the End\n",
        "# dropout_keep_probability        Decrease, Doesn't Affect Much\n",
        "# use_dropout                     If True: Good Loss, Very Bad mAP\n",
        "# l2_regularizer                  Keep as is, Doesn't Affect Much\n",
        "# batch_norm decay                Keep as is, Doesn't Affect Much\n",
        "# feature_extractor min_depth     Increase (+4) !!!!!!!!!!!\n",
        "# initial_learning_rate           Decrease (original: 0.004)  !!!!!!!!!!!\n",
        "# decay_steps                     Increase, but Doesn't Affect Much\n",
        "# decay_factor                    Increase, Affects Much  !!!!!!!!!!!\n",
        "# momentum_optimizer_value        Increase Affects Much,  !!!!!!!!!!!\n",
        "# momentum_optimizer_value decay  Increase Affects Much,  !!!!!!!!!!!         \n",
        "# apply_sigmoid_to_scores         If True: very bad loss, but slightly better mAP\n",
        "# batch_norm epsilon              Keep as is, Doesn't Affect Much\n",
        "# train_config epsilon            Keep as is\n",
        "# box_code_size                   Decrease, but Doesn't Affect Much\n",
        "# batch_size                      Increase, Affects Much !!!!!!!!!!!\n",
        "# hard_example_miner iou_threshold         Decreasing: Very low loss, same mAP !!!!!!!!!!!\n",
        "# hard_example_miner num_hard_examples     Increase, Affects Much   !!!!!!!!!!!\n",
        "# max_negatives_per_positive               Doesn't Affect Much\n",
        "# max_detections_per_class                 Doesn't Affect Much\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "initial_learning_rate = 0.0008    # 0.004 --\n",
        "decay_factor = 0.97               # 0.95 ++\n",
        "momentum_optimizer_value =0.93    # 0.9 ++\n",
        "num_hard_examples = 3000          # 3000 ++\n",
        "batch_size = 12                   # 6, 12 ++\n",
        "\n",
        "iou_threshold = 0.95              # 0.99 --   Manual Change (in hard_example_miner)\n",
        "decay = 0.95                      # 0.9 ++    Manual Change (in momentum_optimizer_value)\n",
        "#min_depth = 20                    # 16 +4     Manual Change (in feature_extractor)\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()    \n",
        "with open(pipeline_fname, 'w') as f:\n",
        "\n",
        "    s = re.sub('initial_learning_rate: [0-9].+', 'initial_learning_rate: {}'.format(initial_learning_rate), s)\n",
        "    s = re.sub('decay_factor: [0-9].+', 'decay_factor: {}'.format(decay_factor), s)\n",
        "    s = re.sub('momentum_optimizer_value: [0-9].+', 'momentum_optimizer_value: {}'.format(momentum_optimizer_value), s)\n",
        "    \n",
        "\n",
        "    f.write(s)\n",
        "\n",
        "!cat {pipeline_fname}   #read pipeline file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 1\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.95\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.0008\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.97\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.93\n",
            "      decay: 0.95\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 5000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/object_detection_demo/data/annotations/train.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/object_detection_demo/data/annotations/test.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XL--jTzF7To",
        "colab_type": "text"
      },
      "source": [
        "**Train The Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sypwJ_D2Pf37",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d0b36b6-beb2-47e8-bec8-09ee7872c689"
      },
      "source": [
        "# Training -- ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚ðŸš‚\n",
        "\n",
        "num_steps = num_steps + 5000        #to continue training from the last checkpoint\n",
        "\n",
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0217 15:37:27.987405 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0217 15:37:27.990781 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0217 15:37:27.990929 140570767890304 model_lib.py:629] Forced number of epochs for all eval validations to be 1.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0217 15:37:27.991056 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 160000\n",
            "I0217 15:37:27.991147 140570767890304 config_util.py:488] Maybe overwriting train_steps: 160000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0217 15:37:27.991243 140570767890304 config_util.py:488] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0217 15:37:27.991320 140570767890304 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0217 15:37:27.991419 140570767890304 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0217 15:37:27.991490 140570767890304 config_util.py:488] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0217 15:37:27.991559 140570767890304 config_util.py:498] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0217 15:37:27.992197 140570767890304 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0217 15:37:27.992301 140570767890304 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd8c6bccf60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0217 15:37:27.992759 140570767890304 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd8c6bccf60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fd8c6bd07b8>) includes params argument, but params are not passed to Estimator.\n",
            "W0217 15:37:27.993009 140570767890304 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fd8c6bd07b8>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0217 15:37:27.993729 140570767890304 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0217 15:37:27.993909 140570767890304 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0217 15:37:27.994126 140570767890304 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0217 15:37:28.003193 140570767890304 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0217 15:37:28.013301 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W0217 15:37:28.013546 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0217 15:37:28.025468 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0217 15:37:28.026287 140570767890304 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0217 15:37:28.031234 140570767890304 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0217 15:37:28.031411 140570767890304 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0217 15:37:28.051779 140570767890304 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
            "\n",
            "W0217 15:37:29.239301 140570767890304 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "W0217 15:37:35.997527 140570767890304 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0217 15:37:36.087167 140570767890304 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0217 15:37:38.099443 140570767890304 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0217 15:37:41.417868 140570767890304 api.py:332] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0217 15:37:44.566418 140570767890304 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "W0217 15:37:44.567471 140570767890304 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0217 15:37:44.950445 140570767890304 deprecation.py:323] From /content/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
            "\n",
            "W0217 15:37:46.686022 140570767890304 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W0217 15:37:47.149204 140570767890304 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0217 15:37:47.161897 140570767890304 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0217 15:37:47.318563 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0217 15:37:47.318902 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0217 15:37:47.321571 140570767890304 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0217 15:37:49.924633 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:37:49.934991 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:37:49.965084 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:37:49.993223 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:37:50.021694 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:37:50.049700 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:37:50.077278 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W0217 15:37:50.111183 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0217 15:37:50.112221 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0217 15:37:50.116505 140570767890304 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n",
            "W0217 15:37:50.116657 140570767890304 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0217 15:37:50.116769 140570767890304 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0217 15:37:50.116877 140570767890304 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0217 15:37:50.117086 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0217 15:37:51.010804 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0217 15:37:52.680418 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W0217 15:37:52.685645 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "W0217 15:37:52.686709 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W0217 15:37:52.976069 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0217 15:37:52.978737 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "W0217 15:37:52.979019 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "W0217 15:37:52.986823 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0217 15:37:52.987051 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0217 15:37:54.845909 140570767890304 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0217 15:38:00.174390 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0217 15:38:00.848603 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "W0217 15:38:00.848872 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0217 15:38:00.849354 140570767890304 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0217 15:38:00.850515 140570767890304 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0217 15:38:04.211729 140570767890304 monitored_session.py:240] Graph was finalized.\n",
            "2020-02-17 15:38:04.225434: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-02-17 15:38:04.227291: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1bc1640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-17 15:38:04.227330: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-17 15:38:04.248283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-17 15:38:04.422968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:38:04.423492: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1bc1100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-17 15:38:04.423522: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-02-17 15:38:04.423962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:38:04.424330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-17 15:38:04.443472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-17 15:38:04.696465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-17 15:38:04.821318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-17 15:38:04.849023: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-17 15:38:05.118166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-17 15:38:05.141141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-17 15:38:05.641801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-17 15:38:05.642055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:38:05.642599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:38:05.642960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-17 15:38:05.646943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-17 15:38:05.648206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-17 15:38:05.648237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-17 15:38:05.648250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-17 15:38:05.649503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:38:05.649969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:38:05.650439: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-02-17 15:38:05.650487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-150000\n",
            "I0217 15:38:05.653072 140570767890304 saver.py:1284] Restoring parameters from training/model.ckpt-150000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0217 15:38:13.317914 140570767890304 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0217 15:38:14.492815 140570767890304 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0217 15:38:14.830826 140570767890304 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 150000 into training/model.ckpt.\n",
            "I0217 15:38:23.637056 140570767890304 basic_session_run_hooks.py:606] Saving checkpoints for 150000 into training/model.ckpt.\n",
            "2020-02-17 15:38:31.846210: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 24883200 exceeds 10% of system memory.\n",
            "2020-02-17 15:38:31.856080: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 24883200 exceeds 10% of system memory.\n",
            "2020-02-17 15:38:31.869530: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 24883200 exceeds 10% of system memory.\n",
            "2020-02-17 15:38:31.953660: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 24883200 exceeds 10% of system memory.\n",
            "2020-02-17 15:38:31.961518: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 24883200 exceeds 10% of system memory.\n",
            "2020-02-17 15:38:34.365544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-17 15:38:38.988762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:loss = 1.1789874, step = 150000\n",
            "I0217 15:38:41.916887 140570767890304 basic_session_run_hooks.py:262] loss = 1.1789874, step = 150000\n",
            "INFO:tensorflow:global_step/sec: 2.13385\n",
            "I0217 15:39:28.779578 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.13385\n",
            "INFO:tensorflow:loss = 1.0382762, step = 150100 (46.864 sec)\n",
            "I0217 15:39:28.780766 140570767890304 basic_session_run_hooks.py:260] loss = 1.0382762, step = 150100 (46.864 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.3185\n",
            "I0217 15:40:11.910744 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.3185\n",
            "INFO:tensorflow:loss = 1.8011558, step = 150200 (43.131 sec)\n",
            "I0217 15:40:11.911872 140570767890304 basic_session_run_hooks.py:260] loss = 1.8011558, step = 150200 (43.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.32113\n",
            "I0217 15:40:54.993241 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.32113\n",
            "INFO:tensorflow:loss = 1.7309291, step = 150300 (43.082 sec)\n",
            "I0217 15:40:54.994343 140570767890304 basic_session_run_hooks.py:260] loss = 1.7309291, step = 150300 (43.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35688\n",
            "I0217 15:41:37.422157 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35688\n",
            "INFO:tensorflow:loss = 1.4146389, step = 150400 (42.429 sec)\n",
            "I0217 15:41:37.423342 140570767890304 basic_session_run_hooks.py:260] loss = 1.4146389, step = 150400 (42.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34952\n",
            "I0217 15:42:19.984043 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34952\n",
            "INFO:tensorflow:loss = 1.5421139, step = 150500 (42.562 sec)\n",
            "I0217 15:42:19.985191 140570767890304 basic_session_run_hooks.py:260] loss = 1.5421139, step = 150500 (42.562 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35562\n",
            "I0217 15:43:02.435832 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35562\n",
            "INFO:tensorflow:loss = 0.58976734, step = 150600 (42.452 sec)\n",
            "I0217 15:43:02.437216 140570767890304 basic_session_run_hooks.py:260] loss = 0.58976734, step = 150600 (42.452 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36283\n",
            "I0217 15:43:44.757906 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36283\n",
            "INFO:tensorflow:loss = 1.2513576, step = 150700 (42.322 sec)\n",
            "I0217 15:43:44.759027 140570767890304 basic_session_run_hooks.py:260] loss = 1.2513576, step = 150700 (42.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.37297\n",
            "I0217 15:44:26.899240 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.37297\n",
            "INFO:tensorflow:loss = 1.8002102, step = 150800 (42.141 sec)\n",
            "I0217 15:44:26.900379 140570767890304 basic_session_run_hooks.py:260] loss = 1.8002102, step = 150800 (42.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36444\n",
            "I0217 15:45:09.192614 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36444\n",
            "INFO:tensorflow:loss = 1.1192157, step = 150900 (42.294 sec)\n",
            "I0217 15:45:09.194753 140570767890304 basic_session_run_hooks.py:260] loss = 1.1192157, step = 150900 (42.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35811\n",
            "I0217 15:45:51.599509 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35811\n",
            "INFO:tensorflow:loss = 0.82167554, step = 151000 (42.406 sec)\n",
            "I0217 15:45:51.600487 140570767890304 basic_session_run_hooks.py:260] loss = 0.82167554, step = 151000 (42.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35516\n",
            "I0217 15:46:34.059557 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35516\n",
            "INFO:tensorflow:loss = 1.1150389, step = 151100 (42.460 sec)\n",
            "I0217 15:46:34.060962 140570767890304 basic_session_run_hooks.py:260] loss = 1.1150389, step = 151100 (42.460 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35812\n",
            "I0217 15:47:16.466200 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35812\n",
            "INFO:tensorflow:loss = 2.5264812, step = 151200 (42.406 sec)\n",
            "I0217 15:47:16.467411 140570767890304 basic_session_run_hooks.py:260] loss = 2.5264812, step = 151200 (42.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36013\n",
            "I0217 15:47:58.836798 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36013\n",
            "INFO:tensorflow:loss = 1.808843, step = 151300 (42.370 sec)\n",
            "I0217 15:47:58.837773 140570767890304 basic_session_run_hooks.py:260] loss = 1.808843, step = 151300 (42.370 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 151365 into training/model.ckpt.\n",
            "I0217 15:48:25.890169 140570767890304 basic_session_run_hooks.py:606] Saving checkpoints for 151365 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0217 15:48:28.227654 140570767890304 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:48:30.304982 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:48:30.334475 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:48:30.363437 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:48:30.392721 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:48:30.421932 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:48:30.450774 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0217 15:48:31.099025 140570767890304 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0217 15:48:31.291933 140570767890304 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "W0217 15:48:31.440587 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "W0217 15:48:31.520767 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0217 15:48:31.801876 140570767890304 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-02-17T15:48:31Z\n",
            "I0217 15:48:31.821770 140570767890304 evaluation.py:255] Starting evaluation at 2020-02-17T15:48:31Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0217 15:48:32.467874 140570767890304 monitored_session.py:240] Graph was finalized.\n",
            "2020-02-17 15:48:32.469204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:48:32.469554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-17 15:48:32.469676: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-17 15:48:32.469703: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-17 15:48:32.469730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-17 15:48:32.469754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-17 15:48:32.469775: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-17 15:48:32.469799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-17 15:48:32.469826: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-17 15:48:32.469910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:48:32.470218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:48:32.470473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-17 15:48:32.470525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-17 15:48:32.470539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-17 15:48:32.470548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-17 15:48:32.470644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:48:32.470938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:48:32.471189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-151365\n",
            "I0217 15:48:32.472439 140570767890304 saver.py:1284] Restoring parameters from training/model.ckpt-151365\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0217 15:48:33.396917 140570767890304 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0217 15:48:33.533004 140570767890304 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 269 images.\n",
            "I0217 15:48:58.586116 140567202539264 coco_evaluation.py:205] Performing evaluation on 269 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0217 15:48:58.587741 140567202539264 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0217 15:48:58.604091 140567202539264 coco_tools.py:137] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.39s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.22s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.796\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.425\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.510\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.558\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647\n",
            "INFO:tensorflow:Finished evaluation at 2020-02-17-15:49:01\n",
            "I0217 15:49:01.321790 140570767890304 evaluation.py:275] Finished evaluation at 2020-02-17-15:49:01\n",
            "INFO:tensorflow:Saving dict for global step 151365: DetectionBoxes_Precision/mAP = 0.43517682, DetectionBoxes_Precision/mAP (large) = 0.555175, DetectionBoxes_Precision/mAP (medium) = 0.17115532, DetectionBoxes_Precision/mAP (small) = 0.02970297, DetectionBoxes_Precision/mAP@.50IOU = 0.7963958, DetectionBoxes_Precision/mAP@.75IOU = 0.42471796, DetectionBoxes_Recall/AR@1 = 0.5095941, DetectionBoxes_Recall/AR@10 = 0.54760146, DetectionBoxes_Recall/AR@100 = 0.55793357, DetectionBoxes_Recall/AR@100 (large) = 0.6467662, DetectionBoxes_Recall/AR@100 (medium) = 0.33333334, DetectionBoxes_Recall/AR@100 (small) = 0.028571429, Loss/classification_loss = 4.2604995, Loss/localization_loss = 1.4081471, Loss/regularization_loss = 0.38060537, Loss/total_loss = 6.0492516, global_step = 151365, learning_rate = 0.0008, loss = 6.0492516\n",
            "I0217 15:49:01.322065 140570767890304 estimator.py:2049] Saving dict for global step 151365: DetectionBoxes_Precision/mAP = 0.43517682, DetectionBoxes_Precision/mAP (large) = 0.555175, DetectionBoxes_Precision/mAP (medium) = 0.17115532, DetectionBoxes_Precision/mAP (small) = 0.02970297, DetectionBoxes_Precision/mAP@.50IOU = 0.7963958, DetectionBoxes_Precision/mAP@.75IOU = 0.42471796, DetectionBoxes_Recall/AR@1 = 0.5095941, DetectionBoxes_Recall/AR@10 = 0.54760146, DetectionBoxes_Recall/AR@100 = 0.55793357, DetectionBoxes_Recall/AR@100 (large) = 0.6467662, DetectionBoxes_Recall/AR@100 (medium) = 0.33333334, DetectionBoxes_Recall/AR@100 (small) = 0.028571429, Loss/classification_loss = 4.2604995, Loss/localization_loss = 1.4081471, Loss/regularization_loss = 0.38060537, Loss/total_loss = 6.0492516, global_step = 151365, learning_rate = 0.0008, loss = 6.0492516\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 151365: training/model.ckpt-151365\n",
            "I0217 15:49:02.123321 140570767890304 estimator.py:2109] Saving 'checkpoint_path' summary for global step 151365: training/model.ckpt-151365\n",
            "INFO:tensorflow:global_step/sec: 1.27563\n",
            "I0217 15:49:17.229641 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 1.27563\n",
            "INFO:tensorflow:loss = 2.120689, step = 151400 (78.393 sec)\n",
            "I0217 15:49:17.230634 140570767890304 basic_session_run_hooks.py:260] loss = 2.120689, step = 151400 (78.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34357\n",
            "I0217 15:49:59.899539 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34357\n",
            "INFO:tensorflow:loss = 2.3261046, step = 151500 (42.670 sec)\n",
            "I0217 15:49:59.900610 140570767890304 basic_session_run_hooks.py:260] loss = 2.3261046, step = 151500 (42.670 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36849\n",
            "I0217 15:50:42.120499 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36849\n",
            "INFO:tensorflow:loss = 1.6800286, step = 151600 (42.221 sec)\n",
            "I0217 15:50:42.121496 140570767890304 basic_session_run_hooks.py:260] loss = 1.6800286, step = 151600 (42.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35327\n",
            "I0217 15:51:24.614540 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35327\n",
            "INFO:tensorflow:loss = 2.4984012, step = 151700 (42.494 sec)\n",
            "I0217 15:51:24.615863 140570767890304 basic_session_run_hooks.py:260] loss = 2.4984012, step = 151700 (42.494 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.33064\n",
            "I0217 15:52:07.521154 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.33064\n",
            "INFO:tensorflow:loss = 1.0734813, step = 151800 (42.906 sec)\n",
            "I0217 15:52:07.522259 140570767890304 basic_session_run_hooks.py:260] loss = 1.0734813, step = 151800 (42.906 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.3563\n",
            "I0217 15:52:49.960611 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.3563\n",
            "INFO:tensorflow:loss = 2.5707352, step = 151900 (42.440 sec)\n",
            "I0217 15:52:49.961858 140570767890304 basic_session_run_hooks.py:260] loss = 2.5707352, step = 151900 (42.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.32266\n",
            "I0217 15:53:33.014776 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.32266\n",
            "INFO:tensorflow:loss = 2.4620857, step = 152000 (43.054 sec)\n",
            "I0217 15:53:33.015906 140570767890304 basic_session_run_hooks.py:260] loss = 2.4620857, step = 152000 (43.054 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35121\n",
            "I0217 15:54:15.545987 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35121\n",
            "INFO:tensorflow:loss = 1.717924, step = 152100 (42.531 sec)\n",
            "I0217 15:54:15.547125 140570767890304 basic_session_run_hooks.py:260] loss = 1.717924, step = 152100 (42.531 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36743\n",
            "I0217 15:54:57.785853 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36743\n",
            "INFO:tensorflow:loss = 2.6801803, step = 152200 (42.240 sec)\n",
            "I0217 15:54:57.786767 140570767890304 basic_session_run_hooks.py:260] loss = 2.6801803, step = 152200 (42.240 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34274\n",
            "I0217 15:55:40.470834 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34274\n",
            "INFO:tensorflow:loss = 1.5536098, step = 152300 (42.685 sec)\n",
            "I0217 15:55:40.472202 140570767890304 basic_session_run_hooks.py:260] loss = 1.5536098, step = 152300 (42.685 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.32556\n",
            "I0217 15:56:23.471329 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.32556\n",
            "INFO:tensorflow:loss = 2.466276, step = 152400 (43.001 sec)\n",
            "I0217 15:56:23.472705 140570767890304 basic_session_run_hooks.py:260] loss = 2.466276, step = 152400 (43.001 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34035\n",
            "I0217 15:57:06.200066 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34035\n",
            "INFO:tensorflow:loss = 1.6818233, step = 152500 (42.728 sec)\n",
            "I0217 15:57:06.201074 140570767890304 basic_session_run_hooks.py:260] loss = 1.6818233, step = 152500 (42.728 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.3232\n",
            "I0217 15:57:49.244045 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.3232\n",
            "INFO:tensorflow:loss = 1.1219661, step = 152600 (43.044 sec)\n",
            "I0217 15:57:49.245498 140570767890304 basic_session_run_hooks.py:260] loss = 1.1219661, step = 152600 (43.044 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 152687 into training/model.ckpt.\n",
            "I0217 15:58:26.106854 140570767890304 basic_session_run_hooks.py:606] Saving checkpoints for 152687 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0217 15:58:28.274749 140570767890304 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:58:30.319024 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:58:30.349607 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:58:30.380081 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:58:30.412791 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:58:30.444109 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 15:58:30.472802 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0217 15:58:31.791672 140570767890304 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-02-17T15:58:31Z\n",
            "I0217 15:58:31.807993 140570767890304 evaluation.py:255] Starting evaluation at 2020-02-17T15:58:31Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0217 15:58:32.229465 140570767890304 monitored_session.py:240] Graph was finalized.\n",
            "2020-02-17 15:58:32.230215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:58:32.230590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-17 15:58:32.230704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-17 15:58:32.230724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-17 15:58:32.230738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-17 15:58:32.230752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-17 15:58:32.230769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-17 15:58:32.230783: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-17 15:58:32.230796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-17 15:58:32.230863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:58:32.231146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:58:32.231383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-17 15:58:32.231480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-17 15:58:32.231490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-17 15:58:32.231500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-17 15:58:32.231587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:58:32.231857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 15:58:32.232098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-152687\n",
            "I0217 15:58:32.233177 140570767890304 saver.py:1284] Restoring parameters from training/model.ckpt-152687\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0217 15:58:33.121760 140570767890304 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0217 15:58:33.248998 140570767890304 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 269 images.\n",
            "I0217 15:58:58.047287 140568658048768 coco_evaluation.py:205] Performing evaluation on 269 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0217 15:58:58.048650 140568658048768 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0217 15:58:58.066236 140568658048768 coco_tools.py:137] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.39s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.21s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.808\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.461\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.556\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.517\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.549\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.560\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643\n",
            "INFO:tensorflow:Finished evaluation at 2020-02-17-15:59:00\n",
            "I0217 15:59:00.775043 140570767890304 evaluation.py:275] Finished evaluation at 2020-02-17-15:59:00\n",
            "INFO:tensorflow:Saving dict for global step 152687: DetectionBoxes_Precision/mAP = 0.43994856, DetectionBoxes_Precision/mAP (large) = 0.55556375, DetectionBoxes_Precision/mAP (medium) = 0.18983705, DetectionBoxes_Precision/mAP (small) = 0.029912146, DetectionBoxes_Precision/mAP@.50IOU = 0.8082807, DetectionBoxes_Precision/mAP@.75IOU = 0.46111068, DetectionBoxes_Recall/AR@1 = 0.51697415, DetectionBoxes_Recall/AR@10 = 0.5494465, DetectionBoxes_Recall/AR@100 = 0.5597786, DetectionBoxes_Recall/AR@100 (large) = 0.6432836, DetectionBoxes_Recall/AR@100 (medium) = 0.34920636, DetectionBoxes_Recall/AR@100 (small) = 0.057142857, Loss/classification_loss = 4.125564, Loss/localization_loss = 1.4334238, Loss/regularization_loss = 0.38029465, Loss/total_loss = 5.939284, global_step = 152687, learning_rate = 0.0008, loss = 5.939284\n",
            "I0217 15:59:00.775308 140570767890304 estimator.py:2049] Saving dict for global step 152687: DetectionBoxes_Precision/mAP = 0.43994856, DetectionBoxes_Precision/mAP (large) = 0.55556375, DetectionBoxes_Precision/mAP (medium) = 0.18983705, DetectionBoxes_Precision/mAP (small) = 0.029912146, DetectionBoxes_Precision/mAP@.50IOU = 0.8082807, DetectionBoxes_Precision/mAP@.75IOU = 0.46111068, DetectionBoxes_Recall/AR@1 = 0.51697415, DetectionBoxes_Recall/AR@10 = 0.5494465, DetectionBoxes_Recall/AR@100 = 0.5597786, DetectionBoxes_Recall/AR@100 (large) = 0.6432836, DetectionBoxes_Recall/AR@100 (medium) = 0.34920636, DetectionBoxes_Recall/AR@100 (small) = 0.057142857, Loss/classification_loss = 4.125564, Loss/localization_loss = 1.4334238, Loss/regularization_loss = 0.38029465, Loss/total_loss = 5.939284, global_step = 152687, learning_rate = 0.0008, loss = 5.939284\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 152687: training/model.ckpt-152687\n",
            "I0217 15:59:00.778160 140570767890304 estimator.py:2109] Saving 'checkpoint_path' summary for global step 152687: training/model.ckpt-152687\n",
            "INFO:tensorflow:global_step/sec: 1.28886\n",
            "I0217 15:59:06.832134 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 1.28886\n",
            "INFO:tensorflow:loss = 3.49087, step = 152700 (77.588 sec)\n",
            "I0217 15:59:06.833021 140570767890304 basic_session_run_hooks.py:260] loss = 3.49087, step = 152700 (77.588 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.32998\n",
            "I0217 15:59:49.750962 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.32998\n",
            "INFO:tensorflow:loss = 1.5670023, step = 152800 (42.919 sec)\n",
            "I0217 15:59:49.752084 140570767890304 basic_session_run_hooks.py:260] loss = 1.5670023, step = 152800 (42.919 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34749\n",
            "I0217 16:00:32.349695 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34749\n",
            "INFO:tensorflow:loss = 1.9921732, step = 152900 (42.599 sec)\n",
            "I0217 16:00:32.350783 140570767890304 basic_session_run_hooks.py:260] loss = 1.9921732, step = 152900 (42.599 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.33841\n",
            "I0217 16:01:15.113851 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.33841\n",
            "INFO:tensorflow:loss = 1.4305742, step = 153000 (42.764 sec)\n",
            "I0217 16:01:15.115120 140570767890304 basic_session_run_hooks.py:260] loss = 1.4305742, step = 153000 (42.764 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.33391\n",
            "I0217 16:01:57.960515 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.33391\n",
            "INFO:tensorflow:loss = 1.6475065, step = 153100 (42.847 sec)\n",
            "I0217 16:01:57.961894 140570767890304 basic_session_run_hooks.py:260] loss = 1.6475065, step = 153100 (42.847 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.32544\n",
            "I0217 16:02:40.963042 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.32544\n",
            "INFO:tensorflow:loss = 0.7708263, step = 153200 (43.002 sec)\n",
            "I0217 16:02:40.964221 140570767890304 basic_session_run_hooks.py:260] loss = 0.7708263, step = 153200 (43.002 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35528\n",
            "I0217 16:03:23.420968 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35528\n",
            "INFO:tensorflow:loss = 1.3232377, step = 153300 (42.458 sec)\n",
            "I0217 16:03:23.422094 140570767890304 basic_session_run_hooks.py:260] loss = 1.3232377, step = 153300 (42.458 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.32764\n",
            "I0217 16:04:06.382817 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.32764\n",
            "INFO:tensorflow:loss = 1.0777547, step = 153400 (42.962 sec)\n",
            "I0217 16:04:06.384017 140570767890304 basic_session_run_hooks.py:260] loss = 1.0777547, step = 153400 (42.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.33426\n",
            "I0217 16:04:49.223026 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.33426\n",
            "INFO:tensorflow:loss = 2.9307935, step = 153500 (42.840 sec)\n",
            "I0217 16:04:49.224141 140570767890304 basic_session_run_hooks.py:260] loss = 2.9307935, step = 153500 (42.840 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35537\n",
            "I0217 16:05:31.679178 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35537\n",
            "INFO:tensorflow:loss = 1.383269, step = 153600 (42.456 sec)\n",
            "I0217 16:05:31.680143 140570767890304 basic_session_run_hooks.py:260] loss = 1.383269, step = 153600 (42.456 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34755\n",
            "I0217 16:06:14.276708 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34755\n",
            "INFO:tensorflow:loss = 1.4246407, step = 153700 (42.598 sec)\n",
            "I0217 16:06:14.278111 140570767890304 basic_session_run_hooks.py:260] loss = 1.4246407, step = 153700 (42.598 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.32985\n",
            "I0217 16:06:57.197988 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.32985\n",
            "INFO:tensorflow:loss = 0.92211026, step = 153800 (42.921 sec)\n",
            "I0217 16:06:57.199323 140570767890304 basic_session_run_hooks.py:260] loss = 0.92211026, step = 153800 (42.921 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34545\n",
            "I0217 16:07:39.833715 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34545\n",
            "INFO:tensorflow:loss = 1.9012702, step = 153900 (42.635 sec)\n",
            "I0217 16:07:39.834780 140570767890304 basic_session_run_hooks.py:260] loss = 1.9012702, step = 153900 (42.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.33638\n",
            "I0217 16:08:22.634930 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.33638\n",
            "INFO:tensorflow:loss = 2.8381305, step = 154000 (42.801 sec)\n",
            "I0217 16:08:22.635881 140570767890304 basic_session_run_hooks.py:260] loss = 2.8381305, step = 154000 (42.801 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 154009 into training/model.ckpt.\n",
            "I0217 16:08:26.152906 140570767890304 basic_session_run_hooks.py:606] Saving checkpoints for 154009 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0217 16:08:28.389870 140570767890304 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:08:30.448253 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:08:30.479275 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:08:30.508354 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:08:30.537178 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:08:30.566261 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:08:30.594645 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0217 16:08:31.907668 140570767890304 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-02-17T16:08:31Z\n",
            "I0217 16:08:31.924717 140570767890304 evaluation.py:255] Starting evaluation at 2020-02-17T16:08:31Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0217 16:08:32.345989 140570767890304 monitored_session.py:240] Graph was finalized.\n",
            "2020-02-17 16:08:32.346675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:08:32.347011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-17 16:08:32.347127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-17 16:08:32.347159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-17 16:08:32.347202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-17 16:08:32.347238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-17 16:08:32.347261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-17 16:08:32.347286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-17 16:08:32.347312: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-17 16:08:32.347424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:08:32.347768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:08:32.348006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-17 16:08:32.348090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-17 16:08:32.348104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-17 16:08:32.348114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-17 16:08:32.348215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:08:32.348529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:08:32.348781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-154009\n",
            "I0217 16:08:32.349851 140570767890304 saver.py:1284] Restoring parameters from training/model.ckpt-154009\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0217 16:08:33.278835 140570767890304 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0217 16:08:33.410440 140570767890304 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 269 images.\n",
            "I0217 16:08:58.217537 140568658048768 coco_evaluation.py:205] Performing evaluation on 269 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0217 16:08:58.220067 140568658048768 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0217 16:08:58.239098 140568658048768 coco_tools.py:137] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.36s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.21s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.783\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.425\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.173\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.549\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.557\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647\n",
            "INFO:tensorflow:Finished evaluation at 2020-02-17-16:09:00\n",
            "I0217 16:09:00.923662 140570767890304 evaluation.py:275] Finished evaluation at 2020-02-17-16:09:00\n",
            "INFO:tensorflow:Saving dict for global step 154009: DetectionBoxes_Precision/mAP = 0.44254565, DetectionBoxes_Precision/mAP (large) = 0.5641693, DetectionBoxes_Precision/mAP (medium) = 0.1732835, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.7828559, DetectionBoxes_Precision/mAP@.75IOU = 0.42452097, DetectionBoxes_Recall/AR@1 = 0.5188192, DetectionBoxes_Recall/AR@10 = 0.5494465, DetectionBoxes_Recall/AR@100 = 0.55719554, DetectionBoxes_Recall/AR@100 (large) = 0.6467662, DetectionBoxes_Recall/AR@100 (medium) = 0.33333334, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 4.1809278, Loss/localization_loss = 1.4203261, Loss/regularization_loss = 0.37998214, Loss/total_loss = 5.9812374, global_step = 154009, learning_rate = 0.0008, loss = 5.9812374\n",
            "I0217 16:09:00.923936 140570767890304 estimator.py:2049] Saving dict for global step 154009: DetectionBoxes_Precision/mAP = 0.44254565, DetectionBoxes_Precision/mAP (large) = 0.5641693, DetectionBoxes_Precision/mAP (medium) = 0.1732835, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.7828559, DetectionBoxes_Precision/mAP@.75IOU = 0.42452097, DetectionBoxes_Recall/AR@1 = 0.5188192, DetectionBoxes_Recall/AR@10 = 0.5494465, DetectionBoxes_Recall/AR@100 = 0.55719554, DetectionBoxes_Recall/AR@100 (large) = 0.6467662, DetectionBoxes_Recall/AR@100 (medium) = 0.33333334, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 4.1809278, Loss/localization_loss = 1.4203261, Loss/regularization_loss = 0.37998214, Loss/total_loss = 5.9812374, global_step = 154009, learning_rate = 0.0008, loss = 5.9812374\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 154009: training/model.ckpt-154009\n",
            "I0217 16:09:00.926903 140570767890304 estimator.py:2109] Saving 'checkpoint_path' summary for global step 154009: training/model.ckpt-154009\n",
            "INFO:tensorflow:global_step/sec: 1.28439\n",
            "I0217 16:09:40.492954 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 1.28439\n",
            "INFO:tensorflow:loss = 1.0672123, step = 154100 (77.859 sec)\n",
            "I0217 16:09:40.495334 140570767890304 basic_session_run_hooks.py:260] loss = 1.0672123, step = 154100 (77.859 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36936\n",
            "I0217 16:10:22.699435 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36936\n",
            "INFO:tensorflow:loss = 0.8568833, step = 154200 (42.205 sec)\n",
            "I0217 16:10:22.700712 140570767890304 basic_session_run_hooks.py:260] loss = 0.8568833, step = 154200 (42.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.38056\n",
            "I0217 16:11:04.705340 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.38056\n",
            "INFO:tensorflow:loss = 1.1721528, step = 154300 (42.006 sec)\n",
            "I0217 16:11:04.706434 140570767890304 basic_session_run_hooks.py:260] loss = 1.1721528, step = 154300 (42.006 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35715\n",
            "I0217 16:11:47.129502 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35715\n",
            "INFO:tensorflow:loss = 1.2698897, step = 154400 (42.424 sec)\n",
            "I0217 16:11:47.130663 140570767890304 basic_session_run_hooks.py:260] loss = 1.2698897, step = 154400 (42.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.33688\n",
            "I0217 16:12:29.921644 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.33688\n",
            "INFO:tensorflow:loss = 1.6827409, step = 154500 (42.794 sec)\n",
            "I0217 16:12:29.924196 140570767890304 basic_session_run_hooks.py:260] loss = 1.6827409, step = 154500 (42.794 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36616\n",
            "I0217 16:13:12.184235 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36616\n",
            "INFO:tensorflow:loss = 1.0921715, step = 154600 (42.261 sec)\n",
            "I0217 16:13:12.185322 140570767890304 basic_session_run_hooks.py:260] loss = 1.0921715, step = 154600 (42.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.37553\n",
            "I0217 16:13:54.280173 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.37553\n",
            "INFO:tensorflow:loss = 2.0150862, step = 154700 (42.096 sec)\n",
            "I0217 16:13:54.281317 140570767890304 basic_session_run_hooks.py:260] loss = 2.0150862, step = 154700 (42.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35953\n",
            "I0217 16:14:36.661542 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35953\n",
            "INFO:tensorflow:loss = 1.7246189, step = 154800 (42.381 sec)\n",
            "I0217 16:14:36.662677 140570767890304 basic_session_run_hooks.py:260] loss = 1.7246189, step = 154800 (42.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34212\n",
            "I0217 16:15:19.357914 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34212\n",
            "INFO:tensorflow:loss = 0.83088726, step = 154900 (42.696 sec)\n",
            "I0217 16:15:19.359083 140570767890304 basic_session_run_hooks.py:260] loss = 0.83088726, step = 154900 (42.696 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.37631\n",
            "I0217 16:16:01.439896 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.37631\n",
            "INFO:tensorflow:loss = 1.513576, step = 155000 (42.082 sec)\n",
            "I0217 16:16:01.441101 140570767890304 basic_session_run_hooks.py:260] loss = 1.513576, step = 155000 (42.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35012\n",
            "I0217 16:16:43.990962 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35012\n",
            "INFO:tensorflow:loss = 1.3784946, step = 155100 (42.551 sec)\n",
            "I0217 16:16:43.992203 140570767890304 basic_session_run_hooks.py:260] loss = 1.3784946, step = 155100 (42.551 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36083\n",
            "I0217 16:17:26.348899 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36083\n",
            "INFO:tensorflow:loss = 1.5546633, step = 155200 (42.358 sec)\n",
            "I0217 16:17:26.349974 140570767890304 basic_session_run_hooks.py:260] loss = 1.5546633, step = 155200 (42.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34468\n",
            "I0217 16:18:08.998675 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34468\n",
            "INFO:tensorflow:loss = 1.4590836, step = 155300 (42.650 sec)\n",
            "I0217 16:18:08.999601 140570767890304 basic_session_run_hooks.py:260] loss = 1.4590836, step = 155300 (42.650 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 155342 into training/model.ckpt.\n",
            "I0217 16:18:26.428298 140570767890304 basic_session_run_hooks.py:606] Saving checkpoints for 155342 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0217 16:18:28.634212 140570767890304 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:18:30.687061 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:18:30.715874 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:18:30.744578 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:18:30.773469 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:18:30.802188 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:18:30.830210 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0217 16:18:32.188856 140570767890304 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-02-17T16:18:32Z\n",
            "I0217 16:18:32.204448 140570767890304 evaluation.py:255] Starting evaluation at 2020-02-17T16:18:32Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0217 16:18:32.622836 140570767890304 monitored_session.py:240] Graph was finalized.\n",
            "2020-02-17 16:18:32.623685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:18:32.624025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-17 16:18:32.624124: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-17 16:18:32.624154: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-17 16:18:32.624177: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-17 16:18:32.624203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-17 16:18:32.624228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-17 16:18:32.624248: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-17 16:18:32.624269: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-17 16:18:32.624347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:18:32.624708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:18:32.624960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-17 16:18:32.625096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-17 16:18:32.625112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-17 16:18:32.625122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-17 16:18:32.625217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:18:32.625547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:18:32.625813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-155342\n",
            "I0217 16:18:32.626903 140570767890304 saver.py:1284] Restoring parameters from training/model.ckpt-155342\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0217 16:18:33.522615 140570767890304 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0217 16:18:33.655256 140570767890304 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 269 images.\n",
            "I0217 16:18:57.823012 140567202539264 coco_evaluation.py:205] Performing evaluation on 269 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0217 16:18:57.823984 140567202539264 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0217 16:18:57.841092 140567202539264 coco_tools.py:137] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.30s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.812\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.410\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.543\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629\n",
            "INFO:tensorflow:Finished evaluation at 2020-02-17-16:19:00\n",
            "I0217 16:19:00.449081 140570767890304 evaluation.py:275] Finished evaluation at 2020-02-17-16:19:00\n",
            "INFO:tensorflow:Saving dict for global step 155342: DetectionBoxes_Precision/mAP = 0.43065637, DetectionBoxes_Precision/mAP (large) = 0.55151904, DetectionBoxes_Precision/mAP (medium) = 0.15877913, DetectionBoxes_Precision/mAP (small) = 0.044554457, DetectionBoxes_Precision/mAP@.50IOU = 0.8116159, DetectionBoxes_Precision/mAP@.75IOU = 0.41005227, DetectionBoxes_Recall/AR@1 = 0.5059041, DetectionBoxes_Recall/AR@10 = 0.5328413, DetectionBoxes_Recall/AR@100 = 0.5428044, DetectionBoxes_Recall/AR@100 (large) = 0.6293532, DetectionBoxes_Recall/AR@100 (medium) = 0.32222223, DetectionBoxes_Recall/AR@100 (small) = 0.042857144, Loss/classification_loss = 4.2827, Loss/localization_loss = 1.4208659, Loss/regularization_loss = 0.3796711, Loss/total_loss = 6.083238, global_step = 155342, learning_rate = 0.0008, loss = 6.083238\n",
            "I0217 16:19:00.449343 140570767890304 estimator.py:2049] Saving dict for global step 155342: DetectionBoxes_Precision/mAP = 0.43065637, DetectionBoxes_Precision/mAP (large) = 0.55151904, DetectionBoxes_Precision/mAP (medium) = 0.15877913, DetectionBoxes_Precision/mAP (small) = 0.044554457, DetectionBoxes_Precision/mAP@.50IOU = 0.8116159, DetectionBoxes_Precision/mAP@.75IOU = 0.41005227, DetectionBoxes_Recall/AR@1 = 0.5059041, DetectionBoxes_Recall/AR@10 = 0.5328413, DetectionBoxes_Recall/AR@100 = 0.5428044, DetectionBoxes_Recall/AR@100 (large) = 0.6293532, DetectionBoxes_Recall/AR@100 (medium) = 0.32222223, DetectionBoxes_Recall/AR@100 (small) = 0.042857144, Loss/classification_loss = 4.2827, Loss/localization_loss = 1.4208659, Loss/regularization_loss = 0.3796711, Loss/total_loss = 6.083238, global_step = 155342, learning_rate = 0.0008, loss = 6.083238\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 155342: training/model.ckpt-155342\n",
            "I0217 16:19:00.452236 140570767890304 estimator.py:2109] Saving 'checkpoint_path' summary for global step 155342: training/model.ckpt-155342\n",
            "INFO:tensorflow:global_step/sec: 1.30805\n",
            "I0217 16:19:25.448569 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 1.30805\n",
            "INFO:tensorflow:loss = 3.3987699, step = 155400 (76.450 sec)\n",
            "I0217 16:19:25.449703 140570767890304 basic_session_run_hooks.py:260] loss = 3.3987699, step = 155400 (76.450 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34361\n",
            "I0217 16:20:08.117771 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34361\n",
            "INFO:tensorflow:loss = 1.3333335, step = 155500 (42.669 sec)\n",
            "I0217 16:20:08.118697 140570767890304 basic_session_run_hooks.py:260] loss = 1.3333335, step = 155500 (42.669 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.3521\n",
            "I0217 16:20:50.632962 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.3521\n",
            "INFO:tensorflow:loss = 1.9052233, step = 155600 (42.515 sec)\n",
            "I0217 16:20:50.633989 140570767890304 basic_session_run_hooks.py:260] loss = 1.9052233, step = 155600 (42.515 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35211\n",
            "I0217 16:21:33.147959 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35211\n",
            "INFO:tensorflow:loss = 1.4902875, step = 155700 (42.515 sec)\n",
            "I0217 16:21:33.149186 140570767890304 basic_session_run_hooks.py:260] loss = 1.4902875, step = 155700 (42.515 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35191\n",
            "I0217 16:22:15.666502 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35191\n",
            "INFO:tensorflow:loss = 0.9176816, step = 155800 (42.518 sec)\n",
            "I0217 16:22:15.667466 140570767890304 basic_session_run_hooks.py:260] loss = 0.9176816, step = 155800 (42.518 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.32684\n",
            "I0217 16:22:58.643287 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.32684\n",
            "INFO:tensorflow:loss = 1.1711658, step = 155900 (42.977 sec)\n",
            "I0217 16:22:58.644346 140570767890304 basic_session_run_hooks.py:260] loss = 1.1711658, step = 155900 (42.977 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.33462\n",
            "I0217 16:23:41.476737 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.33462\n",
            "INFO:tensorflow:loss = 1.4940665, step = 156000 (42.834 sec)\n",
            "I0217 16:23:41.477906 140570767890304 basic_session_run_hooks.py:260] loss = 1.4940665, step = 156000 (42.834 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34295\n",
            "I0217 16:24:24.158008 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34295\n",
            "INFO:tensorflow:loss = 1.0110164, step = 156100 (42.681 sec)\n",
            "I0217 16:24:24.158985 140570767890304 basic_session_run_hooks.py:260] loss = 1.0110164, step = 156100 (42.681 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35657\n",
            "I0217 16:25:06.592693 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35657\n",
            "INFO:tensorflow:loss = 2.8686166, step = 156200 (42.435 sec)\n",
            "I0217 16:25:06.593726 140570767890304 basic_session_run_hooks.py:260] loss = 2.8686166, step = 156200 (42.435 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.33401\n",
            "I0217 16:25:49.437461 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.33401\n",
            "INFO:tensorflow:loss = 1.9344032, step = 156300 (42.845 sec)\n",
            "I0217 16:25:49.438466 140570767890304 basic_session_run_hooks.py:260] loss = 1.9344032, step = 156300 (42.845 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35229\n",
            "I0217 16:26:31.949159 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35229\n",
            "INFO:tensorflow:loss = 1.7236971, step = 156400 (42.512 sec)\n",
            "I0217 16:26:31.950249 140570767890304 basic_session_run_hooks.py:260] loss = 1.7236971, step = 156400 (42.512 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34101\n",
            "I0217 16:27:14.665702 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34101\n",
            "INFO:tensorflow:loss = 2.8134089, step = 156500 (42.717 sec)\n",
            "I0217 16:27:14.666753 140570767890304 basic_session_run_hooks.py:260] loss = 2.8134089, step = 156500 (42.717 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.33636\n",
            "I0217 16:27:57.467355 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.33636\n",
            "INFO:tensorflow:loss = 2.4690773, step = 156600 (42.802 sec)\n",
            "I0217 16:27:57.468583 140570767890304 basic_session_run_hooks.py:260] loss = 2.4690773, step = 156600 (42.802 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 156669 into training/model.ckpt.\n",
            "I0217 16:28:26.431678 140570767890304 basic_session_run_hooks.py:606] Saving checkpoints for 156669 into training/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0217 16:28:26.530901 140570767890304 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0217 16:28:27.970176 140570767890304 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 2.25923\n",
            "I0217 16:28:41.730193 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.25923\n",
            "INFO:tensorflow:loss = 1.7959938, step = 156700 (44.263 sec)\n",
            "I0217 16:28:41.731223 140570767890304 basic_session_run_hooks.py:260] loss = 1.7959938, step = 156700 (44.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.37401\n",
            "I0217 16:29:23.853079 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.37401\n",
            "INFO:tensorflow:loss = 1.2442445, step = 156800 (42.123 sec)\n",
            "I0217 16:29:23.854052 140570767890304 basic_session_run_hooks.py:260] loss = 1.2442445, step = 156800 (42.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.32833\n",
            "I0217 16:30:06.802244 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.32833\n",
            "INFO:tensorflow:loss = 0.9003182, step = 156900 (42.950 sec)\n",
            "I0217 16:30:06.803672 140570767890304 basic_session_run_hooks.py:260] loss = 0.9003182, step = 156900 (42.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36346\n",
            "I0217 16:30:49.113068 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36346\n",
            "INFO:tensorflow:loss = 2.5808089, step = 157000 (42.311 sec)\n",
            "I0217 16:30:49.114222 140570767890304 basic_session_run_hooks.py:260] loss = 2.5808089, step = 157000 (42.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34342\n",
            "I0217 16:31:31.785760 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34342\n",
            "INFO:tensorflow:loss = 1.2315081, step = 157100 (42.673 sec)\n",
            "I0217 16:31:31.786780 140570767890304 basic_session_run_hooks.py:260] loss = 1.2315081, step = 157100 (42.673 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34655\n",
            "I0217 16:32:14.401594 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34655\n",
            "INFO:tensorflow:loss = 0.67063594, step = 157200 (42.616 sec)\n",
            "I0217 16:32:14.402532 140570767890304 basic_session_run_hooks.py:260] loss = 0.67063594, step = 157200 (42.616 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35498\n",
            "I0217 16:32:56.864831 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35498\n",
            "INFO:tensorflow:loss = 1.5985286, step = 157300 (42.464 sec)\n",
            "I0217 16:32:56.866035 140570767890304 basic_session_run_hooks.py:260] loss = 1.5985286, step = 157300 (42.464 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36273\n",
            "I0217 16:33:39.188845 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36273\n",
            "INFO:tensorflow:loss = 1.1318256, step = 157400 (42.324 sec)\n",
            "I0217 16:33:39.189853 140570767890304 basic_session_run_hooks.py:260] loss = 1.1318256, step = 157400 (42.324 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.33978\n",
            "I0217 16:34:21.927866 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.33978\n",
            "INFO:tensorflow:loss = 1.0084702, step = 157500 (42.739 sec)\n",
            "I0217 16:34:21.928905 140570767890304 basic_session_run_hooks.py:260] loss = 1.0084702, step = 157500 (42.739 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35464\n",
            "I0217 16:35:04.397297 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35464\n",
            "INFO:tensorflow:loss = 1.5893801, step = 157600 (42.470 sec)\n",
            "I0217 16:35:04.398469 140570767890304 basic_session_run_hooks.py:260] loss = 1.5893801, step = 157600 (42.470 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.31961\n",
            "I0217 16:35:47.508046 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.31961\n",
            "INFO:tensorflow:loss = 1.7251015, step = 157700 (43.111 sec)\n",
            "I0217 16:35:47.509075 140570767890304 basic_session_run_hooks.py:260] loss = 1.7251015, step = 157700 (43.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.39264\n",
            "I0217 16:36:29.302815 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.39264\n",
            "INFO:tensorflow:loss = 1.5558051, step = 157800 (41.796 sec)\n",
            "I0217 16:36:29.304917 140570767890304 basic_session_run_hooks.py:260] loss = 1.5558051, step = 157800 (41.796 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.3509\n",
            "I0217 16:37:11.839901 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.3509\n",
            "INFO:tensorflow:loss = 0.6931232, step = 157900 (42.536 sec)\n",
            "I0217 16:37:11.841207 140570767890304 basic_session_run_hooks.py:260] loss = 0.6931232, step = 157900 (42.536 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36334\n",
            "I0217 16:37:54.152833 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36334\n",
            "INFO:tensorflow:loss = 1.7609432, step = 158000 (42.313 sec)\n",
            "I0217 16:37:54.153744 140570767890304 basic_session_run_hooks.py:260] loss = 1.7609432, step = 158000 (42.313 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 158078 into training/model.ckpt.\n",
            "I0217 16:38:26.680408 140570767890304 basic_session_run_hooks.py:606] Saving checkpoints for 158078 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0217 16:38:28.900098 140570767890304 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:38:31.351605 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:38:31.386166 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:38:31.416108 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:38:31.445463 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:38:31.479037 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:38:31.508285 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0217 16:38:32.873898 140570767890304 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-02-17T16:38:32Z\n",
            "I0217 16:38:32.890428 140570767890304 evaluation.py:255] Starting evaluation at 2020-02-17T16:38:32Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0217 16:38:33.295343 140570767890304 monitored_session.py:240] Graph was finalized.\n",
            "2020-02-17 16:38:33.296321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:38:33.296717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-17 16:38:33.296835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-17 16:38:33.296854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-17 16:38:33.296869: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-17 16:38:33.296884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-17 16:38:33.296898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-17 16:38:33.296912: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-17 16:38:33.296944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-17 16:38:33.297028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:38:33.297312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:38:33.297561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-17 16:38:33.297722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-17 16:38:33.297741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-17 16:38:33.297751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-17 16:38:33.297850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:38:33.298134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:38:33.298405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-158078\n",
            "I0217 16:38:33.299709 140570767890304 saver.py:1284] Restoring parameters from training/model.ckpt-158078\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0217 16:38:34.258304 140570767890304 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0217 16:38:34.395529 140570767890304 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 269 images.\n",
            "I0217 16:38:58.690901 140567202539264 coco_evaluation.py:205] Performing evaluation on 269 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0217 16:38:58.691805 140567202539264 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0217 16:38:58.707679 140567202539264 coco_tools.py:137] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.32s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.21s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.784\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.415\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.153\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.559\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.503\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.548\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635\n",
            "INFO:tensorflow:Finished evaluation at 2020-02-17-16:39:01\n",
            "I0217 16:39:01.352884 140570767890304 evaluation.py:275] Finished evaluation at 2020-02-17-16:39:01\n",
            "INFO:tensorflow:Saving dict for global step 158078: DetectionBoxes_Precision/mAP = 0.42469743, DetectionBoxes_Precision/mAP (large) = 0.5594558, DetectionBoxes_Precision/mAP (medium) = 0.15287232, DetectionBoxes_Precision/mAP (small) = 0.0005940594, DetectionBoxes_Precision/mAP@.50IOU = 0.7838132, DetectionBoxes_Precision/mAP@.75IOU = 0.414664, DetectionBoxes_Recall/AR@1 = 0.50332105, DetectionBoxes_Recall/AR@10 = 0.53357935, DetectionBoxes_Recall/AR@100 = 0.5483395, DetectionBoxes_Recall/AR@100 (large) = 0.6353234, DetectionBoxes_Recall/AR@100 (medium) = 0.32857144, DetectionBoxes_Recall/AR@100 (small) = 0.028571429, Loss/classification_loss = 4.299285, Loss/localization_loss = 1.4567455, Loss/regularization_loss = 0.37903413, Loss/total_loss = 6.1350636, global_step = 158078, learning_rate = 0.0008, loss = 6.1350636\n",
            "I0217 16:39:01.353219 140570767890304 estimator.py:2049] Saving dict for global step 158078: DetectionBoxes_Precision/mAP = 0.42469743, DetectionBoxes_Precision/mAP (large) = 0.5594558, DetectionBoxes_Precision/mAP (medium) = 0.15287232, DetectionBoxes_Precision/mAP (small) = 0.0005940594, DetectionBoxes_Precision/mAP@.50IOU = 0.7838132, DetectionBoxes_Precision/mAP@.75IOU = 0.414664, DetectionBoxes_Recall/AR@1 = 0.50332105, DetectionBoxes_Recall/AR@10 = 0.53357935, DetectionBoxes_Recall/AR@100 = 0.5483395, DetectionBoxes_Recall/AR@100 (large) = 0.6353234, DetectionBoxes_Recall/AR@100 (medium) = 0.32857144, DetectionBoxes_Recall/AR@100 (small) = 0.028571429, Loss/classification_loss = 4.299285, Loss/localization_loss = 1.4567455, Loss/regularization_loss = 0.37903413, Loss/total_loss = 6.1350636, global_step = 158078, learning_rate = 0.0008, loss = 6.1350636\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 158078: training/model.ckpt-158078\n",
            "I0217 16:39:01.356034 140570767890304 estimator.py:2109] Saving 'checkpoint_path' summary for global step 158078: training/model.ckpt-158078\n",
            "INFO:tensorflow:global_step/sec: 1.29784\n",
            "I0217 16:39:11.203768 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 1.29784\n",
            "INFO:tensorflow:loss = 1.4246364, step = 158100 (77.051 sec)\n",
            "I0217 16:39:11.204889 140570767890304 basic_session_run_hooks.py:260] loss = 1.4246364, step = 158100 (77.051 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36612\n",
            "I0217 16:39:53.467081 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36612\n",
            "INFO:tensorflow:loss = 1.4920185, step = 158200 (42.264 sec)\n",
            "I0217 16:39:53.468992 140570767890304 basic_session_run_hooks.py:260] loss = 1.4920185, step = 158200 (42.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36583\n",
            "I0217 16:40:35.735701 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36583\n",
            "INFO:tensorflow:loss = 2.2998388, step = 158300 (42.268 sec)\n",
            "I0217 16:40:35.736884 140570767890304 basic_session_run_hooks.py:260] loss = 2.2998388, step = 158300 (42.268 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35614\n",
            "I0217 16:41:18.178076 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35614\n",
            "INFO:tensorflow:loss = 1.0815041, step = 158400 (42.443 sec)\n",
            "I0217 16:41:18.179472 140570767890304 basic_session_run_hooks.py:260] loss = 1.0815041, step = 158400 (42.443 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34396\n",
            "I0217 16:42:00.840858 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34396\n",
            "INFO:tensorflow:loss = 0.9286564, step = 158500 (42.662 sec)\n",
            "I0217 16:42:00.841776 140570767890304 basic_session_run_hooks.py:260] loss = 0.9286564, step = 158500 (42.662 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.3657\n",
            "I0217 16:42:43.111664 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.3657\n",
            "INFO:tensorflow:loss = 3.253371, step = 158600 (42.271 sec)\n",
            "I0217 16:42:43.112915 140570767890304 basic_session_run_hooks.py:260] loss = 3.253371, step = 158600 (42.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.36707\n",
            "I0217 16:43:25.357876 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.36707\n",
            "INFO:tensorflow:loss = 1.3655984, step = 158700 (42.246 sec)\n",
            "I0217 16:43:25.359121 140570767890304 basic_session_run_hooks.py:260] loss = 1.3655984, step = 158700 (42.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.33057\n",
            "I0217 16:44:08.265755 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.33057\n",
            "INFO:tensorflow:loss = 1.1928235, step = 158800 (42.908 sec)\n",
            "I0217 16:44:08.266784 140570767890304 basic_session_run_hooks.py:260] loss = 1.1928235, step = 158800 (42.908 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34807\n",
            "I0217 16:44:50.854052 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34807\n",
            "INFO:tensorflow:loss = 1.0334878, step = 158900 (42.588 sec)\n",
            "I0217 16:44:50.855092 140570767890304 basic_session_run_hooks.py:260] loss = 1.0334878, step = 158900 (42.588 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35816\n",
            "I0217 16:45:33.259914 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35816\n",
            "INFO:tensorflow:loss = 1.7331054, step = 159000 (42.406 sec)\n",
            "I0217 16:45:33.261291 140570767890304 basic_session_run_hooks.py:260] loss = 1.7331054, step = 159000 (42.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.3452\n",
            "I0217 16:46:15.900277 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.3452\n",
            "INFO:tensorflow:loss = 1.9797071, step = 159100 (42.641 sec)\n",
            "I0217 16:46:15.902423 140570767890304 basic_session_run_hooks.py:260] loss = 1.9797071, step = 159100 (42.641 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35111\n",
            "I0217 16:46:58.433452 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35111\n",
            "INFO:tensorflow:loss = 1.6612184, step = 159200 (42.539 sec)\n",
            "I0217 16:46:58.440943 140570767890304 basic_session_run_hooks.py:260] loss = 1.6612184, step = 159200 (42.539 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.37381\n",
            "I0217 16:47:40.559772 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.37381\n",
            "INFO:tensorflow:loss = 1.8784717, step = 159300 (42.120 sec)\n",
            "I0217 16:47:40.561148 140570767890304 basic_session_run_hooks.py:260] loss = 1.8784717, step = 159300 (42.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.35263\n",
            "I0217 16:48:23.065417 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.35263\n",
            "INFO:tensorflow:loss = 1.63677, step = 159400 (42.505 sec)\n",
            "I0217 16:48:23.066528 140570767890304 basic_session_run_hooks.py:260] loss = 1.63677, step = 159400 (42.505 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 159410 into training/model.ckpt.\n",
            "I0217 16:48:26.784651 140570767890304 basic_session_run_hooks.py:606] Saving checkpoints for 159410 into training/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0217 16:48:29.031758 140570767890304 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:48:31.104188 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:48:31.134501 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:48:31.163958 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:48:31.192342 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:48:31.221682 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:48:31.251924 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0217 16:48:32.874652 140570767890304 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-02-17T16:48:32Z\n",
            "I0217 16:48:32.890883 140570767890304 evaluation.py:255] Starting evaluation at 2020-02-17T16:48:32Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0217 16:48:33.299810 140570767890304 monitored_session.py:240] Graph was finalized.\n",
            "2020-02-17 16:48:33.300543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:48:33.300892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-17 16:48:33.301037: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-17 16:48:33.301072: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-17 16:48:33.301102: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-17 16:48:33.301125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-17 16:48:33.301145: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-17 16:48:33.301169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-17 16:48:33.301193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-17 16:48:33.301276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:48:33.301654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:48:33.301909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-17 16:48:33.301957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-17 16:48:33.301971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-17 16:48:33.301981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-17 16:48:33.302106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:48:33.302423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:48:33.302729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-159410\n",
            "I0217 16:48:33.303978 140570767890304 saver.py:1284] Restoring parameters from training/model.ckpt-159410\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0217 16:48:34.237778 140570767890304 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0217 16:48:34.372937 140570767890304 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 269 images.\n",
            "I0217 16:48:59.258561 140567202539264 coco_evaluation.py:205] Performing evaluation on 269 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0217 16:48:59.259747 140567202539264 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0217 16:48:59.278347 140567202539264 coco_tools.py:137] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.33s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.21s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.750\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.401\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.634\n",
            "INFO:tensorflow:Finished evaluation at 2020-02-17-16:49:01\n",
            "I0217 16:49:01.943482 140570767890304 evaluation.py:275] Finished evaluation at 2020-02-17-16:49:01\n",
            "INFO:tensorflow:Saving dict for global step 159410: DetectionBoxes_Precision/mAP = 0.40185988, DetectionBoxes_Precision/mAP (large) = 0.5399172, DetectionBoxes_Precision/mAP (medium) = 0.13699593, DetectionBoxes_Precision/mAP (small) = 0.044554457, DetectionBoxes_Precision/mAP@.50IOU = 0.75005037, DetectionBoxes_Precision/mAP@.75IOU = 0.40071085, DetectionBoxes_Recall/AR@1 = 0.49520296, DetectionBoxes_Recall/AR@10 = 0.52693725, DetectionBoxes_Recall/AR@100 = 0.54428047, DetectionBoxes_Recall/AR@100 (large) = 0.63432837, DetectionBoxes_Recall/AR@100 (medium) = 0.31269842, DetectionBoxes_Recall/AR@100 (small) = 0.042857144, Loss/classification_loss = 4.4666524, Loss/localization_loss = 1.4296278, Loss/regularization_loss = 0.37872258, Loss/total_loss = 6.275002, global_step = 159410, learning_rate = 0.0008, loss = 6.275002\n",
            "I0217 16:49:01.943800 140570767890304 estimator.py:2049] Saving dict for global step 159410: DetectionBoxes_Precision/mAP = 0.40185988, DetectionBoxes_Precision/mAP (large) = 0.5399172, DetectionBoxes_Precision/mAP (medium) = 0.13699593, DetectionBoxes_Precision/mAP (small) = 0.044554457, DetectionBoxes_Precision/mAP@.50IOU = 0.75005037, DetectionBoxes_Precision/mAP@.75IOU = 0.40071085, DetectionBoxes_Recall/AR@1 = 0.49520296, DetectionBoxes_Recall/AR@10 = 0.52693725, DetectionBoxes_Recall/AR@100 = 0.54428047, DetectionBoxes_Recall/AR@100 (large) = 0.63432837, DetectionBoxes_Recall/AR@100 (medium) = 0.31269842, DetectionBoxes_Recall/AR@100 (small) = 0.042857144, Loss/classification_loss = 4.4666524, Loss/localization_loss = 1.4296278, Loss/regularization_loss = 0.37872258, Loss/total_loss = 6.275002, global_step = 159410, learning_rate = 0.0008, loss = 6.275002\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 159410: training/model.ckpt-159410\n",
            "I0217 16:49:01.946670 140570767890304 estimator.py:2109] Saving 'checkpoint_path' summary for global step 159410: training/model.ckpt-159410\n",
            "INFO:tensorflow:global_step/sec: 1.28591\n",
            "I0217 16:49:40.831332 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 1.28591\n",
            "INFO:tensorflow:loss = 1.9689447, step = 159500 (77.766 sec)\n",
            "I0217 16:49:40.832846 140570767890304 basic_session_run_hooks.py:260] loss = 1.9689447, step = 159500 (77.766 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.38019\n",
            "I0217 16:50:22.844922 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.38019\n",
            "INFO:tensorflow:loss = 1.2124008, step = 159600 (42.014 sec)\n",
            "I0217 16:50:22.846419 140570767890304 basic_session_run_hooks.py:260] loss = 1.2124008, step = 159600 (42.014 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.31976\n",
            "I0217 16:51:05.952746 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.31976\n",
            "INFO:tensorflow:loss = 0.95554316, step = 159700 (43.108 sec)\n",
            "I0217 16:51:05.954242 140570767890304 basic_session_run_hooks.py:260] loss = 0.95554316, step = 159700 (43.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.38754\n",
            "I0217 16:51:47.836813 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.38754\n",
            "INFO:tensorflow:loss = 0.80146766, step = 159800 (41.884 sec)\n",
            "I0217 16:51:47.838058 140570767890304 basic_session_run_hooks.py:260] loss = 0.80146766, step = 159800 (41.884 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.34353\n",
            "I0217 16:52:30.507515 140570767890304 basic_session_run_hooks.py:692] global_step/sec: 2.34353\n",
            "INFO:tensorflow:loss = 1.8433814, step = 159900 (42.671 sec)\n",
            "I0217 16:52:30.508574 140570767890304 basic_session_run_hooks.py:260] loss = 1.8433814, step = 159900 (42.671 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 160000 into training/model.ckpt.\n",
            "I0217 16:53:12.697032 140570767890304 basic_session_run_hooks.py:606] Saving checkpoints for 160000 into training/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0217 16:53:14.181420 140570767890304 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0217 16:53:14.822783 140570767890304 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:53:16.890934 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:53:16.920292 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:53:16.948051 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:53:16.976197 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:53:17.004651 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:53:17.032853 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0217 16:53:18.669135 140570767890304 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-02-17T16:53:18Z\n",
            "I0217 16:53:18.685312 140570767890304 evaluation.py:255] Starting evaluation at 2020-02-17T16:53:18Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0217 16:53:19.084270 140570767890304 monitored_session.py:240] Graph was finalized.\n",
            "2020-02-17 16:53:19.084999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:53:19.085398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-17 16:53:19.085516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-17 16:53:19.085544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-17 16:53:19.085573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-17 16:53:19.085596: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-17 16:53:19.085618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-17 16:53:19.085644: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-17 16:53:19.085670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-17 16:53:19.085754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:53:19.086077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:53:19.086344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-17 16:53:19.086403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-17 16:53:19.086435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-17 16:53:19.086445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-17 16:53:19.086544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:53:19.086902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:53:19.087181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-160000\n",
            "I0217 16:53:19.088417 140570767890304 saver.py:1284] Restoring parameters from training/model.ckpt-160000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0217 16:53:20.054169 140570767890304 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0217 16:53:20.196474 140570767890304 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 269 images.\n",
            "I0217 16:53:44.841841 140568658048768 coco_evaluation.py:205] Performing evaluation on 269 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0217 16:53:44.842866 140568658048768 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I0217 16:53:44.861430 140568658048768 coco_tools.py:137] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.45s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.832\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.470\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.568\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.383\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.651\n",
            "INFO:tensorflow:Finished evaluation at 2020-02-17-16:53:47\n",
            "I0217 16:53:47.630348 140570767890304 evaluation.py:275] Finished evaluation at 2020-02-17-16:53:47\n",
            "INFO:tensorflow:Saving dict for global step 160000: DetectionBoxes_Precision/mAP = 0.4590287, DetectionBoxes_Precision/mAP (large) = 0.56673485, DetectionBoxes_Precision/mAP (medium) = 0.20996271, DetectionBoxes_Precision/mAP (small) = 0.09251158, DetectionBoxes_Precision/mAP@.50IOU = 0.8324715, DetectionBoxes_Precision/mAP@.75IOU = 0.4702896, DetectionBoxes_Recall/AR@1 = 0.52140224, DetectionBoxes_Recall/AR@10 = 0.56752765, DetectionBoxes_Recall/AR@100 = 0.57453877, DetectionBoxes_Recall/AR@100 (large) = 0.6507463, DetectionBoxes_Recall/AR@100 (medium) = 0.3825397, DetectionBoxes_Recall/AR@100 (small) = 0.114285715, Loss/classification_loss = 4.076667, Loss/localization_loss = 1.4094685, Loss/regularization_loss = 0.37858638, Loss/total_loss = 5.864722, global_step = 160000, learning_rate = 0.0008, loss = 5.864722\n",
            "I0217 16:53:47.630680 140570767890304 estimator.py:2049] Saving dict for global step 160000: DetectionBoxes_Precision/mAP = 0.4590287, DetectionBoxes_Precision/mAP (large) = 0.56673485, DetectionBoxes_Precision/mAP (medium) = 0.20996271, DetectionBoxes_Precision/mAP (small) = 0.09251158, DetectionBoxes_Precision/mAP@.50IOU = 0.8324715, DetectionBoxes_Precision/mAP@.75IOU = 0.4702896, DetectionBoxes_Recall/AR@1 = 0.52140224, DetectionBoxes_Recall/AR@10 = 0.56752765, DetectionBoxes_Recall/AR@100 = 0.57453877, DetectionBoxes_Recall/AR@100 (large) = 0.6507463, DetectionBoxes_Recall/AR@100 (medium) = 0.3825397, DetectionBoxes_Recall/AR@100 (small) = 0.114285715, Loss/classification_loss = 4.076667, Loss/localization_loss = 1.4094685, Loss/regularization_loss = 0.37858638, Loss/total_loss = 5.864722, global_step = 160000, learning_rate = 0.0008, loss = 5.864722\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 160000: training/model.ckpt-160000\n",
            "I0217 16:53:47.633636 140570767890304 estimator.py:2109] Saving 'checkpoint_path' summary for global step 160000: training/model.ckpt-160000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0217 16:53:47.634323 140570767890304 exporter.py:410] Performing the final export in the end of training.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:750: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0217 16:53:47.638433 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/inputs.py:750: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0217 16:53:47.837510 140570767890304 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:53:49.944325 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:53:49.974519 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:53:50.002460 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:53:50.030981 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:53:50.062245 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0217 16:53:50.095795 140570767890304 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:426: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W0217 16:53:50.495885 140570767890304 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:426: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0217 16:53:50.733022 140570767890304 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0217 16:53:50.733346 140570767890304 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0217 16:53:50.734070 140570767890304 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0217 16:53:50.734204 140570767890304 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0217 16:53:50.734258 140570767890304 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0217 16:53:50.734303 140570767890304 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0217 16:53:50.734344 140570767890304 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2020-02-17 16:53:50.734824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:53:50.735157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-17 16:53:50.735233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-17 16:53:50.735249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-17 16:53:50.735263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-17 16:53:50.735277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-17 16:53:50.735290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-17 16:53:50.735302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-17 16:53:50.735316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-17 16:53:50.735404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:53:50.735718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:53:50.735947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-17 16:53:50.735981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-17 16:53:50.735991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-17 16:53:50.735999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-17 16:53:50.736066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:53:50.736323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-17 16:53:50.736581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-160000\n",
            "I0217 16:53:50.739087 140570767890304 saver.py:1284] Restoring parameters from training/model.ckpt-160000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0217 16:53:51.224795 140570767890304 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0217 16:53:51.225017 140570767890304 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1581958427'/saved_model.pb\n",
            "I0217 16:53:52.004107 140570767890304 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1581958427'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.8480779.\n",
            "I0217 16:53:52.364765 140570767890304 estimator.py:371] Loss for final step: 0.8480779.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls {model_dir}  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0PWaPtWGEeY",
        "colab_type": "text"
      },
      "source": [
        "**Exporting a Trained Inference Graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exporting a Trained Inference Graph\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2oQOpaLCOEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --------------------------------------------------------------ðŸŽ¥ðŸŽ¥ Video Test ðŸŽ¥ðŸŽ¥--------------------------------------------------------------\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "!ls {output_directory}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ_Tpa-RK3xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Functions to be used in detection\n",
        "\n",
        "PATH_TO_CKPT = '/content/models/research/fine_tuned_model/frozen_inference_graph.pb'               # Path to the .pb file\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname   # Path to the label_map\n",
        "\n",
        "assert os.path.isfile(PATH_TO_CKPT)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "\n",
        "%cd /content/models/research/object_detection  # Change base directory\n",
        "\n",
        "import cv2\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")                                   \n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "# This is needed to display the images.\n",
        "#%matplotlib inline\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "\n",
        "with detection_graph.as_default():                     \n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "def load_image_into_numpy_array(image):         # Function to convert image into numpy array (but not used in detection)\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "def run_inference_for_single_image(image, graph):     # Detection function called in the last cell to perform detection on each frame\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM7o517UGkRU",
        "colab_type": "text"
      },
      "source": [
        "**Test the Model on the Video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_75z8lKcIdwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "sys.stdout.flush()\n",
        "\n",
        "frame_width = 1280\n",
        "frame_height = 720\n",
        "\n",
        "for k in ['02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18']:\n",
        "\n",
        "  TestedOn = 'MobNv1GrSc_FT'\n",
        "  name = 'Agamy_OnFoot_0' + k\n",
        "\n",
        "  outputName = '/content/' + name + '_' + TestedOn + '.avi'\n",
        "\n",
        "  cam = cv2.VideoCapture('/content/drive/My Drive/Bump_Videos/' + name + '.mp4')\n",
        "  out = cv2.VideoWriter(outputName, cv2.VideoWriter_fourcc('M','J','P','G'), 30, (frame_width,frame_height))\n",
        "  frames = int(cam.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "  i=0\n",
        "\n",
        "  while(True): \n",
        "    ret,image = cam.read()    # read an image (frame) from the video (one by one)\n",
        "\n",
        "    if ret:                   # If video isn't finished keep processing\n",
        "      output_dict = run_inference_for_single_image(image, detection_graph)         # Run inference for frames (one by one)\n",
        "\n",
        "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=4)        # Specify the thickness of the box\n",
        "\n",
        "      out.write(image)         # Add the output image to the video\n",
        "\n",
        "      sys.stdout.flush()\n",
        "      print(str(int(i/frames *100)) +'%-',end='\\n',file=sys.stdout, flush=True)\n",
        "      i=i+1\n",
        "    else: \n",
        "        break\n",
        "\n",
        "  # Release all space and windows once done \n",
        "  cam.release() \n",
        "  out.release()\n",
        "  cv2.destroyAllWindows() \n",
        "\n",
        "  shutil.move(outputName,'/content/drive/My Drive/Detection Output')   #save the model on Google Drive"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}